# AL Development Profile - Full Lifecycle Workflow

**Version:** 2.18.0

## ğŸ¯ Core Principles

### 1. Document-Driven Development
**All agents collaborate via markdown documents in `.dev/` directory.**

Main conversation stays clean - agents write detailed results to files, return one-line status updates.

### 2. Project Memory System (Performance Optimization)
**Project context prevents redundant exploration.**

- `.dev/project-context.md` documents project structure, patterns, and objects
- ALL agents read context FIRST before exploration (saves 5-15 min per workflow)
- Agents update context when they learn something new
- Initialize with `/init-context` (one-time 2-3 min setup)

### 3. Smart Workflow Routing
**Match complexity to workflow - avoid overkill for simple changes.**

- See `workflow-routing.md` for classification system
- TRIVIAL (2-5 min): Direct fix, skip all agents
- SIMPLE (5-15 min): Lightweight planning + implementation + review
- MEDIUM (20-40 min): Balanced planning + development, skip testing
- COMPLEX (45-90 min): Full pipeline with comprehensive planning

### 4. Proportional Planning
**Planning detail must match implementation complexity.**

- See `proportional-planning.md` for detailed guidelines
- SIMPLE: 100-150 lines total (no ASCII art, no alternatives analysis)
- MEDIUM: 200-400 lines total (balanced detail)
- COMPLEX: 400-800 lines total (comprehensive documentation)
- Prevents 946-line plans for 3-file changes

## ğŸ“ Development Directory Structure

```
.dev/
â”œâ”€â”€ project-context.md       # Project memory (read first, saves 5-15 min!)
â”œâ”€â”€ 01-requirements.md       # Requirements engineering output
â”œâ”€â”€ 02-solution-plan.md      # Complete solution design + implementation plan
â”œâ”€â”€ 02a-plan-review.md       # Adversarial plan review findings
â”œâ”€â”€ 03-code-review.md        # Code review findings
â”œâ”€â”€ 04-diagnostics.md        # Compiler diagnostics + fixes
â”œâ”€â”€ 05-test-plan.md          # Test strategy and plan
â”œâ”€â”€ 06-test-review.md        # Test review results
â””â”€â”€ session-log.md           # Cross-agent activity log

~/.claude/tasks/             # ğŸ†• Native task persistence (survives sessions!)
```

**ğŸš€ Performance Tip:** Run `/init-context` once to create `project-context.md`. This documents your project structure so agents don't explore from scratch every time, reducing workflow runtime by 40-60%.

## ğŸ”„ Task Coordination System (NEW in v2.13)

**Tasks replace manual workflow tracking with native Claude Code capabilities.**

### Key Benefits
- **Persistence:** Tasks survive session restarts (`~/.claude/tasks/`)
- **Dependencies:** Tasks block/unblock each other automatically
- **Multi-agent:** Subagents share task lists via `CLAUDE_CODE_TASK_LIST_ID`
- **Broadcasting:** Updates sync across all sessions on same list

### Task Structure for Development Cycle
```
Requirements â†’ blocks â†’ Planning â†’ blocks â†’ Development â†’ blocks â†’ Review â†’ blocks â†’ Testing
```

Each phase is a Task with dependencies. Agents update task status as they work.

### Multi-Session Coordination
```bash
# Share task list across sessions/subagents
CLAUDE_CODE_TASK_LIST_ID=<id> claude
```

See `task-coordination.md` for full details.

## ğŸ”„ Development Lifecycle Pipeline

### Complete Workflow Diagram (v2.18 TDD Workflow)

```ascii
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          PHASE 1: PLANNING                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User Request
    â†“
[requirements-engineer] â†’ .dev/01-requirements.md
    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ APPROVAL GATE 1: Requirements     â•‘  User reviews requirements
â•‘ Options: Approve / Refine / Stop  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“ (Approve)
[solution-planner] â†’ .dev/02-solution-plan.md
    â”‚  - Technical design
    â”‚  - Testability Architecture section:
    â”‚    * Dependencies list (database, time, HTTP, etc.)
    â”‚    * Required interfaces with method signatures
    â”‚    * Injection points (where deps passed as params)
    â”‚    * Mockable boundaries
    â”‚    * Pure vs. impure operations
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PLAN REVIEW LOOP                   â”‚
â”‚                                     â”‚
â”‚  [plan-reviewer] â†’ .dev/02a-plan-review.md
â”‚      â†“                              â”‚
â”‚  Decision:                          â”‚
â”‚   â”œâ”€ APPROVED â†’ exit loop           â”‚
â”‚   â””â”€ CHANGES REQUIRED â†’ iterate    â”‚
â”‚         â†“                           â”‚
â”‚   [solution-planner revises]        â”‚
â”‚         â†“                           â”‚
â”‚   [plan-reviewer re-reviews] â”€â”    â”‚
â”‚         â†“                      â”‚    â”‚
â”‚   If not converged â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚   If 3+ cycles â†’ escalate to user  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
[orchestrator] Verify [VERIFY] assumptions
    â”œâ”€ Glob/Grep/MCP to confirm assumptions
    â””â”€ If verification fails â†’ solution-planner revises
    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ APPROVAL GATE 2: Solution Plan    â•‘  User reviews solution + plan review
â•‘ Options: Approve / Refine / Stop  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“ (Approve)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 2: TEST SPECIFICATION                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[orchestrator] Preflight Check: Test Infrastructure
    â”œâ”€ Check: Test runner app exists (isTest: true)
    â”œâ”€ Check: Test dependencies installed (Microsoft Test libs)
    â”œâ”€ Check: Test helpers/mocks structure exists
    â””â”€ If missing â†’ ASK USER to set up or skip
    â†“ (Pass)
[test-engineer] â†’ .dev/05-test-specification.md
    â”‚  - Review solution plan testability architecture
    â”‚  - Flag testability gaps (missing interfaces, hard deps)
    â”‚  - Design test specifications (WHAT to test, not code)
    â”‚  - Unit test specs (pure business logic)
    â”‚  - Integration test specs (workflows)
    â”‚  - Edge case specs (boundaries, errors)
    â”‚  - Test data/mock requirements
    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ APPROVAL GATE 3: Test Strategy    â•‘  User reviews test approach
â•‘ Options: Approve / Refine / Stop  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“ (Approve)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 3: TDD DEVELOPMENT                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[al-developer] TDD Implementation
    â”‚  For each feature in test specification:
    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  â”‚  TDD CYCLE: RED-GREEN-REFACTOR          â”‚
    â”‚  â”‚                                          â”‚
    â”‚  â”‚  1. RED: Write failing test              â”‚
    â”‚  â”‚     - Implement test codeunit            â”‚
    â”‚  â”‚     - Implement mock repositories        â”‚
    â”‚  â”‚     âš ï¸  MANUAL: User deploys to BC      â”‚
    â”‚  â”‚     âš ï¸  MANUAL: User runs test          â”‚
    â”‚  â”‚     âš ï¸  MANUAL: User reports FAIL       â”‚
    â”‚  â”‚     - Test MUST fail (else test is wrong)â”‚
    â”‚  â”‚     - Document in tdd-log.md             â”‚
    â”‚  â”‚                                          â”‚
    â”‚  â”‚  2. GREEN: Make test pass                â”‚
    â”‚  â”‚     - Implement production code          â”‚
    â”‚  â”‚     - Implement real interfaces          â”‚
    â”‚  â”‚     âš ï¸  MANUAL: User deploys to BC      â”‚
    â”‚  â”‚     âš ï¸  MANUAL: User runs test          â”‚
    â”‚  â”‚     âš ï¸  MANUAL: User reports PASS       â”‚
    â”‚  â”‚     - Test MUST pass now                 â”‚
    â”‚  â”‚     - If fails â†’ iterate until pass      â”‚
    â”‚  â”‚     - Document in tdd-log.md             â”‚
    â”‚  â”‚                                          â”‚
    â”‚  â”‚  3. REFACTOR: Improve code quality       â”‚
    â”‚  â”‚     - Extract helpers, add docs          â”‚
    â”‚  â”‚     - No behavior change                 â”‚
    â”‚  â”‚     âš ï¸  MANUAL: User runs ALL tests     â”‚
    â”‚  â”‚     âš ï¸  MANUAL: User reports PASS       â”‚
    â”‚  â”‚     - All tests still pass               â”‚
    â”‚  â”‚     - If fails â†’ revert refactoring      â”‚
    â”‚  â”‚     - Document in tdd-log.md             â”‚
    â”‚  â”‚                                          â”‚
    â”‚  â”‚  Repeat for next test specification â†’   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚  Produces:
    â”‚    - Test codeunits (src/Tests/)
    â”‚    - Production code (src/)
    â”‚    - Mock implementations (src/Tests/Mocks/)
    â”‚    - .dev/03-tdd-log.md (cycle documentation)
    â”‚
    â”‚  âš ï¸  NOTE: Test execution requires BC server deployment
    â”‚      Claude Code cannot automate test execution
    â”‚      Each TDD cycle has manual approval gates
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CODE REVIEW LOOP                   â”‚
â”‚                                     â”‚
â”‚  [code-reviewer] â†’ .dev/03-code-review.md
â”‚      â”‚  - Reviews production code  â”‚
â”‚      â”‚  - Reviews test code        â”‚
â”‚      â”‚  - Validates testability:   â”‚
â”‚      â”‚    * DI compliance           â”‚
â”‚      â”‚    * Interface usage         â”‚
â”‚      â”‚    * Pure function patterns  â”‚
â”‚      â”‚  - Uses Feedback Resolution Protocol
â”‚      â†“                              â”‚
â”‚  [al-developer] Dispositions findings
â”‚      â†“                              â”‚
â”‚  Decision:                          â”‚
â”‚   â”œâ”€ All resolved + "APPROVED" â†’ exit
â”‚   â””â”€ ACCEPT-FIX items remain â†’ iterate
â”‚         â†“                           â”‚
â”‚   [al-developer implements fixes]  â”‚
â”‚         â†“                           â”‚
â”‚   [code-reviewer re-reviews] â”€â”€â”€â”  â”‚
â”‚         â†“                        â”‚  â”‚
â”‚   If no progress 2x â†’ escalate   â”‚  â”‚
â”‚   If same issue 3x â†’ escalate    â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ APPROVAL GATE 4: Code Review      â•‘  User reviews code + findings
â•‘ Options: Approve / Changes / Stop â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“ (Approve)
[diagnostics-fixer] Compile + analyze
    â”‚  Run al-compile
    â”‚  Analyze compiler output
    â”‚  â†’ .dev/04-diagnostics.md
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DIAGNOSTICS LOOP                   â”‚
â”‚                                     â”‚
â”‚  Decision:                          â”‚
â”‚   â”œâ”€ Clean / minor warnings â†’ exit â”‚
â”‚   â”œâ”€ 1-2 errors â†’ fix in loop      â”‚
â”‚   â””â”€ 3+ errors â†’ iterate           â”‚
â”‚         â†“                           â”‚
â”‚   [diagnostics-fixer] Analyze root cause
â”‚         â†“                           â”‚
â”‚   If wrong assumptions â†’ back to Planning
â”‚   If fixable â†’ [al-developer fixes]â”‚
â”‚         â†“                           â”‚
â”‚   [Recompile] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚         â†“                     â”‚     â”‚
â”‚   If not converging â†’ escalateâ”‚     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ APPROVAL GATE 5: Implementation   â•‘  User reviews diagnostics + final code
â•‘ Options: Approve / Fix / Stop     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“ (Approve)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 4: TEST VALIDATION                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[test-reviewer] â†’ .dev/06-test-review.md
    â”‚  - Validate test coverage matches .dev/05-test-specification.md
    â”‚  - Check all specs were implemented
    â”‚  - Review test code quality
    â”‚  - Verify mocks are correct
    â”‚  - Confirm testability standards followed
    â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ FINAL: Tests Validated            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SUPPORT AGENTS (On-Demand)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Available at any phase:
- [bc-expert] - BC specialist consultations via MCP
- [docs-lookup] - Microsoft Docs search via MCP
- [dependency-navigator] - Base app navigation via MCP
- [interview] - Deep requirements gathering

Loop Governance (applies to all loops):
- Progress indicators: ACCEPT-FIX count decreasing, errors decreasing
- Stall detection: If no progress 2 consecutive iterations â†’ escalate
- Escalation triggers: Same feedback 3x, circular dependencies
```

### Quick Summary (v2.18 TDD Workflow)

**Phase 1: Planning**
- requirements-engineer â†’ Requirements
- solution-planner â†’ Architecture + Testability
- plan-reviewer â†’ Adversarial review
- User approval gate

**Phase 2: Test Specification** (NEW)
- Preflight check (test infrastructure)
- test-engineer â†’ Test specifications (WHAT to test)
- User approval gate

**Phase 3: TDD Development**
- al-developer â†’ RED-GREEN-REFACTOR cycles
- Manual test execution by user (BC server required)
- code-reviewer â†’ Validate testability + quality
- diagnostics-fixer â†’ Compilation
- User approval gate

**Phase 4: Test Validation**
- test-reviewer â†’ Coverage validation
- Final approval

### Phase 1: Planning & Design (Traditional View)
```
User Request
    â†“
1. requirements-engineer â†’ 01-requirements.md
    â†“
2. solution-planner â†’ 02-solution-plan.md (uses BC MCP + MS Docs + codebase exploration)
   - Architecture & design rationale
   - Implementation steps & code templates
   - Explicit assumptions list
   - **NEW:** Testability Architecture section
    â†“
3. plan-reviewer â†’ 02a-plan-review.md (adversarial review)
   - Challenges assumptions, finds gaps, checks scope
   - Tags critical assumptions with [VERIFY]
   â”œâ”€ APPROVED â†’ verify [VERIFY] items â†’ user approval gate
   â””â”€ CHANGES REQUIRED â†’ solution-planner revises (max 3 cycles)
```

### Phase 2: Test Specification (NEW in v2.18)
```
4. test-engineer â†’ 05-test-specification.md
   - Reviews solution plan for testability gaps
   - Designs test specifications (not code)
   - Unit tests, integration tests, edge cases
   - User approval gate
```

### Phase 3: TDD Development & Quality (Iterative)
```
5. al-developer â†’ writes test code + production code via TDD
   - RED: Write failing test (user confirms FAIL)
   - GREEN: Write production code (user confirms PASS)
   - REFACTOR: Improve code (user confirms all PASS)
   - Produces: tests + code + tdd-log.md
    â†“
6. code-reviewer â†’ 03-code-review.md (validates testability + quality)
    â”œâ”€ CHANGES REQUIRED â†’ al-developer dispositions & fixes â†’ re-review
    â””â”€ APPROVED â†’ Continue
    â†“
7. diagnostics-fixer â†’ 04-diagnostics.md + auto-fixes safe issues
    â”œâ”€ If complex errors (3+ or logic issues) â†’ ITERATE back to al-developer
    â””â”€ If minor/no errors â†’ Continue to validation

Iteration uses Feedback Resolution Protocol (see feedback-resolution.md).
Stall detection: if no progress for 2 iterations, escalate to user.
```

### Phase 4: Test Validation (Replaces Testing & Validation)
```
8. test-reviewer â†’ 06-test-review.md
   - Validates coverage matches test specification
   - Reviews test quality
    â†“
Done âœ“
```

## ğŸ“‹ Checkpoint Decision Tables

Explicit decision rules at each workflow boundary. Replaces prose-based iteration logic.

| After Step | Condition | Decision |
|------------|-----------|----------|
| Requirements | Clear and complete | â†’ Planning |
| Requirements | Contradicts known constraints | â†’ Pause, confirm with user |
| Solution Plan | Plan-reviewer APPROVED | â†’ Verify [VERIFY] items â†’ User approval gate |
| Solution Plan | Plan-reviewer CHANGES REQUIRED | â†’ Revise plan (max 3 cycles) |
| Solution Plan | Verification fails ([VERIFY] item wrong) | â†’ Revise plan with correct assumptions |
| Solution Plan | Cannot converge after 3 cycles | â†’ Escalate to user |
| Development | Code compiles, review passed | â†’ Diagnostics |
| Code Review | CHANGES REQUIRED (CRITICAL/SERIOUS) | â†’ ITERATE to al-developer |
| Code Review | APPROVED (only MINOR) | â†’ Continue to diagnostics |
| Diagnostics | Clean or minor | â†’ User approval / testing |
| Diagnostics | 3+ complex errors | â†’ ITERATE to al-developer |
| Diagnostics | Wrong root cause revealed | â†’ Back to planning |

## ğŸ”„ Feedback Resolution Protocol

All review agents (plan-reviewer, code-reviewer) use the **Feedback Resolution Protocol** defined in `feedback-resolution.md`.

Key points:
- **Severity levels:** CRITICAL / SERIOUS / MINOR
- **Dispositions:** ACCEPT-FIX / ACCEPT-DEFER / ACKNOWLEDGE / DISMISS
- **CRITICAL must be ACCEPT-FIX** â€” no exceptions
- **DISMISS requires reasoning**
- **Exit condition:** All items dispositioned, no ACCEPT-FIX remaining, reviewer states "APPROVED"

See `feedback-resolution.md` for full protocol.

## ğŸ”’ Loop Governance

Prevents infinite iteration loops with progress tracking and escalation.

### Progress Indicators

At least one of these must improve each iteration:
- Number of open ACCEPT-FIX items decreasing
- Compilation error count decreasing
- Review severity trending down (CRITICAL â†’ SERIOUS â†’ MINOR)

### Stall Detection

**Escalate to user if:**
- No progress for 2 consecutive iterations (same metrics, same findings)
- Same feedback appears 3+ times across iterations
- Circular fix dependencies (fixing A breaks B, fixing B breaks A)
- DISMISS disputed after rebuttal (reviewer and developer disagree)

### Escalation Format

When escalating, present to user:
- What was attempted (iterations so far)
- What's blocking (specific findings that won't resolve)
- Options: manual intervention, change approach, accept current state

## ğŸ›‘ CRITICAL: Approval Gates in Workflows

**When running /dev-cycle or /plan commands, ALWAYS stop for user approval between major phases.**

### Mandatory Approval Points

1. **After Requirements** (01-requirements.md)
   - Read and summarize key findings (3-5 bullets)
   - Use AskUserQuestion: Approve / Refine / Stop
   - Only continue to solution plan if approved

2. **After Solution Plan** (02-solution-plan.md)
   - Read and summarize solution approach + implementation plan (3-5 bullets)
   - Use AskUserQuestion: Approve / Refine / Start Implementation / Stop
   - Only start development if approved

3. **After Code Review** (03-code-review.md)
   - Summarize review findings
   - Use AskUserQuestion: Approve / Fix Issues / Stop
   - Only continue to testing if approved

### Never Auto-Continue

âŒ **WRONG:**
```
Spawning requirements-engineer...
Spawning bc-solution-designer...  â† NO! Wait for approval!
```

âœ… **CORRECT:**
```
Requirements analysis complete â†’ .dev/01-requirements.md

Key findings:
- 5 functional requirements
- 2 BC integration points
- Credit limit validation on sales posting

[Use AskUserQuestion with Approve/Refine/Stop options]

[Wait for user response before spawning solution-planner]
```

### Handling User Responses

- **Approve:** Continue to next phase
- **Refine:** Ask for feedback, re-run same agent with user input
- **Stop:** End workflow, summarize what's complete

### Why This Matters

- User needs to review and validate each phase
- Prevents wasted work if direction is wrong
- Enables iterative refinement
- Builds trust in the system

### Support Agents (On-Demand)
- **bc-expert** - BC specialist consultation (any phase)
- **docs-lookup** - Microsoft docs research (any phase)
- **dependency-navigator** - Base app exploration (any phase)

**Note:** The solution-planner agent uses these MCP tools internally, so you typically don't need to call support agents separately during planning.

## ğŸš€ Quick Start Commands

### Setup (Run Once)
```
/init-context                # Initialize project memory (2-3 min)
                             # Speeds up ALL future workflows by 40-60%
```

### Quick Bug Fix (Fastest âš¡)
```
/fix "Error: Email validation rejects john.doe@example.com"
```
Fast track: locate â†’ fix â†’ verify (2-5 min, no planning/testing)

### Full Development Cycle
```
/dev-cycle "Add customer credit limit validation"
```
Runs entire pipeline: requirements â†’ design â†’ implementation â†’ code â†’ review â†’ diagnostics â†’ tests

### Individual Phases
```
/plan "Feature description"              # Phases 1-2: Planning only
/develop                                  # Phase 2: Development + review
/test                                     # Phase 3: Testing
```

### Workflow Management
```
/status                      # Show current workflow state & progress
```

### On-Demand Agents
```
/bc-expert "How do I implement custom posting routines?"
/docs-lookup "Table extension best practices"
/nav-baseapp "Find all Customer validation events"
```

## ğŸ› ï¸ Available MCP Tools

### BC Code Intelligence MCP
- Domain expertise and BC specialist consultation
- Base app patterns and best practices
- Architecture guidance
- **Tool prefix:** `mcp__bc-code-intelligence-mcp__*`

### Microsoft Docs MCP
- Official Microsoft Learn documentation
- API reference lookup
- AL language documentation
- **Tool prefix:** `mcp__microsoft_docs_mcp__*`

### AL Dependency MCP
- Navigate base app objects
- Explore extension dependencies
- Find object definitions and references
- **Tool prefix:** `mcp__al_dependency_mcp__*`

## âš ï¸ CRITICAL RULE: MCP Tool Usage

**Main conversation must NEVER call MCP tools directly. Only agents use MCP tools.**

âŒ **WRONG** (Main conversation):
```
Claude: [calls mcp__bc-code-intelligence-mcp__ask directly]
Result: 10KB of JSON floods context
```

âœ… **CORRECT** (Agent delegation):
```
Claude: [spawns solution-planner agent]
Agent: [uses MCP tools: get_table_structure, ask_bc_expert, search_docs]
Agent: [writes findings to .dev/02-solution-plan.md]
Agent: [returns "Solution plan complete â†’ .dev/02-solution-plan.md"]
Claude: "Solution designed. Details in .dev/02-solution-plan.md"
```

**Why?** MCP responses can be verbose (KB of JSON). Agents keep main conversation lean by writing details to files.

### Which Agent Uses Which MCP?

| Agent | MCP Tools Used | Purpose |
|-------|----------------|---------|
| `solution-planner` | âœ… All 3 MCPs | Uses AL Dependency, BC Expert, MS Docs during planning |
| `bc-expert` | âœ… BC Intelligence only | On-demand BC consultation (user command) |
| `docs-lookup` | âœ… MS Docs only | On-demand documentation lookup (user command) |
| `dependency-navigator` | âœ… AL Dependency only | On-demand base app exploration (user command) |
| Main conversation | âŒ None | Never uses MCP directly |

**Key principle:** `solution-planner` uses MCP tools automatically during planning. `bc-expert`, `docs-lookup`, and `dependency-navigator` are for user-invoked on-demand consultation via `/bc-expert`, `/docs-lookup`, `/nav-baseapp` commands.

## ğŸ”¨ AL Compilation Tool

**ALWAYS use `al-compile` instead of manual AL compiler commands.**

### Quick Usage
```bash
al-compile                    # Default: compile with all standard analyzers
al-compile --verbose          # Show detailed compilation info
al-compile --analyzers all    # Include ALL analyzers
al-compile --clean            # Clean .alpackages before compile
```

### What It Does Automatically
âœ… **Auto-detects VS Code AL extension** and uses matching compiler version
âœ… **Auto-detects workspace structure** (single vs multi-app)
âœ… **Auto-finds all `.alpackages` directories** for transitive dependencies
âœ… **Auto-applies ruleset files** (workspace or project level)
âœ… **Auto-includes AppSourceCop** if `AppSourceCop.json` exists
âœ… **Warns if AppSourceCop config missing** when explicitly enabled

### Default Analyzers
When you run `al-compile` without options, it includes:
- **CodeCop** - Code quality and best practices
- **UICop** - User interface rules
- **PerTenantExtensionCop** - Extension-specific rules
- **LinterCop** - Additional quality checks
- **AppSourceCop** - Only if `AppSourceCop.json` exists in project

### Options
```bash
--analyzers <mode>    # Analyzer mode:
                      #   default: Standard set (+ AppSourceCop if config exists)
                      #   all: All analyzers including AppSourceCop
                      #   none: No analyzers
                      #   list: Custom comma-separated (e.g., CodeCop,UICop)

--output <file>       # Error log location (default: .dev/compile-errors.log)
--clean               # Clean .alpackages before compiling
--no-parallel         # Disable parallel compilation
--verbose, -v         # Show detailed output
--help, -h           # Show help
```

### Why Use This Instead of Manual AL Commands?

**Manual compilation is complex:**
```bash
# What you'd need to do manually (15+ steps):
1. Find AL extension directory
2. Detect workspace structure
3. Find all .alpackages directories
4. Build semicolon-separated package paths
5. Find all analyzer DLLs
6. Build analyzer arguments
7. Find ruleset files
8. Use correct compiler version (match analyzers)
9. Enable external rulesets
10. Set parallel compilation
... (see diagnostics-fixer.md for full complexity)
```

**With al-compile:**
```bash
al-compile  # Done! All the above handled automatically
```

### Examples

**Basic compile:**
```bash
al-compile
```

**Verbose output to see what's happening:**
```bash
al-compile --verbose
```

**Include all analyzers (even without AppSourceCop.json):**
```bash
al-compile --analyzers all
```

**Custom analyzer selection:**
```bash
al-compile --analyzers "CodeCop,UICop,LinterCop"
```

**Clean and compile:**
```bash
al-compile --clean
```

### Integration with Agents

**diagnostics-fixer agent** automatically uses `al-compile` to:
1. Run compilation with all analyzers
2. Parse error log from `.dev/compile-errors.log`
3. Auto-fix safe issues
4. Recompile to verify fixes

**All agents should use `al-compile` for any compilation needs.**

### Troubleshooting

**If `al-compile` command not found:**
```bash
source ~/.bashrc  # Reload PATH in current terminal
# Or open a new terminal
```

**If analyzers show version warnings:**
- Extension compiler version: `~/.vscode/extensions/ms-dynamics-smb.al-*/bin/linux/alc`
- Analyzer DLLs: `~/.vscode/extensions/ms-dynamics-smb.al-*/bin/Analyzers/`
- Both should match - `al-compile` handles this automatically

## ğŸ¯ Agent Design Principles

### 1. Single Responsibility
Each agent does ONE thing well:
- Requirements engineer extracts requirements
- Designer designs BC integration
- Developer writes code
- Reviewer reviews code

### 2. Read Previous Context
Each agent reads predecessor's output:
```markdown
# In solution-planner agent
1. Read .dev/01-requirements.md
2. Research BC patterns using MCP tools
3. Create comprehensive solution plan (design + implementation)
4. Write to .dev/02-solution-plan.md

# In al-developer agent
1. Read .dev/02-solution-plan.md
2. Implement code following the plan
3. Write AL source files
```

### 3. Minimal Chat Output
Agents return concise status:
```
Solution plan complete â†’ .dev/02-solution-plan.md

Architecture summary:
- 2 table extensions
- 1 event subscriber
- 1 page extension

Implementation summary:
- 4 files to create
- 3 phases
- Ready for development
```

### 4. Update Session Log
Every agent appends to `.dev/session-log.md`:
```markdown
## [Timestamp] solution-planner
- Input: .dev/01-requirements.md
- Consulted BC Intelligence MCP for posting patterns
- Researched MS Docs for event subscribers
- Explored base app objects
- Designed solution with 2 extensions, 1 event
- Planned 4 files in 3 phases
- Output: .dev/02-solution-plan.md
```

### 5. Support Iteration
Agents can be re-invoked:
```
User: "The solution plan needs to use a separate validation codeunit"
Claude: [spawns solution-planner again, reads 01-requirements.md + user feedback]
Agent: [updates .dev/02-solution-plan.md with revised approach]
```

## ğŸ“‹ Agent Capabilities Matrix (v2.18 TDD Workflow)

| Agent | When Runs | Input | Output | MCP Tools |
|-------|-----------|-------|--------|-----------|
| requirements-engineer | Phase 1 | User request | 01-requirements.md | None |
| solution-planner | Phase 1 | 01-requirements.md | 02-solution-plan.md (with testability) | All 3 |
| plan-reviewer | Phase 1 | 02-solution-plan.md | 02a-plan-review.md | None |
| test-engineer | Phase 2 | 01+02 (NO code yet) | 05-test-specification.md | None |
| al-developer | Phase 3 | 02+05 | Tests + Production code + tdd-log | None |
| code-reviewer | Phase 3 | Test + Production code | 03-code-review.md (validates testability) | None |
| diagnostics-fixer | Phase 3 | Compiler output | 04-diagnostics.md | None |
| test-reviewer | Phase 4 | 05 + Test code | 06-test-review.md (validates coverage) | None |

> **Full details:** See `agents/README.md` for complete dependency matrix, tool access, iteration rules, and workflow diagrams.

## ğŸ”§ AL Coding Standards (Quick Reference)

### Object Naming
- **PascalCase** for all objects
- **Prefix** custom objects with company/app abbreviation
- **Table names**: Singular nouns (`Customer`, `SalesHeader`)
- **Page names**: Match table + type suffix (`CustomerCard`, `CustomerList`)
- **Codeunit names**: Descriptive of purpose

### Field Naming
- **PascalCase** for field names
- **Boolean fields**: Start with verbs (`IsBlocked`, `HasCustomer`)
- **Date fields**: End with `Date` (`PostingDate`, `ShipmentDate`)
- **Avoid abbreviations** unless industry standard

### Code Style
- **Explicit typing** - avoid `variant` when possible
- **Local procedures** over global when appropriate
- **Meaningful names** (`Customer` not `Cust`)
- **XML documentation** for public procedures
- **Group variables** logically (parameters, return values, locals)

### AL Best Practices
- **Table extensions** instead of modifying base tables
- **Error handling** with meaningful messages
- **Events (subscribers)** over modifying base code
- **Temporary tables** for processing
- **Validate user input** in pages/APIs
- **Single responsibility** for codeunits

### Performance
- **SetLoadFields** to optimize data loading
- **FindSet** for iteration (not `Find('-')`)
- **Filter before loading** records
- **Cautious with LOCKTABLE** in multi-user scenarios
- **Batch operations** for bulk data

## ğŸ§ª Testable Architecture Standards

**WHY:** With 500+ tests, confidence in test correctness is critical. Only Test-Driven Development provides this confidence. Testable architecture prevents massive redesigns later.

### Core Principles

1. **Dependency Injection** - Accept dependencies, never create internally
2. **Interface-Based Design** - Program to interfaces, not implementations
3. **Pure vs. Impure Separation** - Isolate side effects from business logic
4. **Database Access Isolation** - Repository pattern for all data access

### 1. Dependency Injection Pattern

#### âŒ UNTESTABLE - Direct Dependencies
```al
codeunit 50100 "Credit Limit Validator"
{
    procedure ValidateCreditLimit(CustomerNo: Code[20]): Boolean
    var
        Customer: Record Customer;
        CustLedgerEntry: Record "Cust. Ledger Entry";
        Outstanding: Decimal;
    begin
        // âŒ Direct database access - cannot mock for testing
        Customer.Get(CustomerNo);

        // âŒ Direct database query - cannot test without real data
        CustLedgerEntry.SetRange("Customer No.", CustomerNo);
        CustLedgerEntry.SetRange(Open, true);
        if CustLedgerEntry.FindSet() then
            repeat
                Outstanding += CustLedgerEntry."Remaining Amount";
            until CustLedgerEntry.Next() = 0;

        // âŒ Uses system time - not deterministic
        exit(Outstanding + GetTodaysOrders(CustomerNo) <= Customer.CreditLimit);
    end;
}
```

**Problems:**
- Cannot test without live database
- Cannot mock customer data
- Cannot control "today's date" for testing
- Massive redesign needed to add tests later

#### âœ… TESTABLE - Injected Dependencies
```al
codeunit 50100 "Credit Limit Validator"
{
    procedure ValidateCreditLimit(
        CustomerNo: Code[20];
        CustomerRepository: Interface ICustomerRepository;
        OrderRepository: Interface IOrderRepository;
        TimeProvider: Interface ITimeProvider
    ): Boolean
    var
        Customer: Record Customer;
        Outstanding: Decimal;
        TodaysOrders: Decimal;
    begin
        // âœ… Get customer via repository interface (mockable)
        if not CustomerRepository.TryGetCustomer(CustomerNo, Customer) then
            Error('Customer %1 not found', CustomerNo);

        // âœ… Calculate outstanding via repository (mockable)
        Outstanding := CustomerRepository.GetOutstandingAmount(CustomerNo);

        // âœ… Get today's orders using time provider (deterministic)
        TodaysOrders := OrderRepository.GetOrdersForDate(
            CustomerNo,
            TimeProvider.Today()
        );

        // âœ… Pure business logic - easy to test
        exit(Outstanding + TodaysOrders <= Customer.CreditLimit);
    end;
}
```

**Benefits:**
- Test with mock repositories (no database)
- Control all inputs precisely
- Deterministic test outcomes
- Fast tests (no I/O)

### 2. Interface Definitions

Define interfaces for all external dependencies:

#### ICustomerRepository
```al
interface ICustomerRepository
{
    /// <summary>
    /// Attempt to retrieve a customer record.
    /// </summary>
    procedure TryGetCustomer(CustomerNo: Code[20]; var Customer: Record Customer): Boolean;

    /// <summary>
    /// Calculate total outstanding amount for customer.
    /// </summary>
    procedure GetOutstandingAmount(CustomerNo: Code[20]): Decimal;

    /// <summary>
    /// Check if customer is blocked.
    /// </summary>
    procedure IsBlocked(CustomerNo: Code[20]): Boolean;
}
```

#### IOrderRepository
```al
interface IOrderRepository
{
    /// <summary>
    /// Get total order amounts for customer on specific date.
    /// </summary>
    procedure GetOrdersForDate(CustomerNo: Code[20]; OrderDate: Date): Decimal;

    /// <summary>
    /// Get all open orders for customer.
    /// </summary>
    procedure GetOpenOrders(CustomerNo: Code[20]; var SalesHeader: Record "Sales Header"): Boolean;
}
```

#### ITimeProvider
```al
interface ITimeProvider
{
    /// <summary>
    /// Get current date (mockable for tests).
    /// </summary>
    procedure Today(): Date;

    /// <summary>
    /// Get current time (mockable for tests).
    /// </summary>
    procedure Now(): Time;
}
```

#### Implementation Codeunits
```al
codeunit 50101 "Customer Repository" implements ICustomerRepository
{
    // Real implementation using database
    procedure TryGetCustomer(CustomerNo: Code[20]; var Customer: Record Customer): Boolean
    begin
        exit(Customer.Get(CustomerNo));
    end;

    procedure GetOutstandingAmount(CustomerNo: Code[20]): Decimal
    var
        CustLedgerEntry: Record "Cust. Ledger Entry";
        Outstanding: Decimal;
    begin
        CustLedgerEntry.SetRange("Customer No.", CustomerNo);
        CustLedgerEntry.SetRange(Open, true);
        if CustLedgerEntry.FindSet() then
            repeat
                Outstanding += CustLedgerEntry."Remaining Amount";
            until CustLedgerEntry.Next() = 0;
        exit(Outstanding);
    end;

    // ... other implementations
}

codeunit 50102 "System Time Provider" implements ITimeProvider
{
    // Real implementation using system
    procedure Today(): Date
    begin
        exit(WorkDate());
    end;

    procedure Now(): Time
    begin
        exit(Time());
    end;
}

codeunit 50103 "Mock Customer Repository" implements ICustomerRepository
{
    // Test implementation with predictable data
    var
        MockCustomers: List of [Record Customer];
        MockOutstanding: Dictionary of [Code[20], Decimal];

    procedure AddMockCustomer(Customer: Record Customer; Outstanding: Decimal)
    begin
        MockCustomers.Add(Customer);
        MockOutstanding.Add(Customer."No.", Outstanding);
    end;

    procedure TryGetCustomer(CustomerNo: Code[20]; var Customer: Record Customer): Boolean
    var
        MockCust: Record Customer;
    begin
        foreach MockCust in MockCustomers do
            if MockCust."No." = CustomerNo then begin
                Customer := MockCust;
                exit(true);
            end;
        exit(false);
    end;

    procedure GetOutstandingAmount(CustomerNo: Code[20]): Decimal
    begin
        if MockOutstanding.ContainsKey(CustomerNo) then
            exit(MockOutstanding.Get(CustomerNo));
        exit(0);
    end;

    // ... other mock implementations
}
```

### 3. Pure vs. Impure Functions

#### Pure Functions (Preferred)
- **Input:** Only parameters
- **Output:** Only return value
- **No side effects:** No database, no global state, no I/O
- **Deterministic:** Same input = same output always

```al
// âœ… Pure function - easy to test
procedure CalculateCreditUtilization(Outstanding: Decimal; CreditLimit: Decimal): Decimal
begin
    if CreditLimit = 0 then
        exit(0); // Unlimited
    exit((Outstanding / CreditLimit) * 100);
end;

// âœ… Pure function - testable logic
procedure DetermineCreditStatus(Utilization: Decimal; WarningThreshold: Decimal): Enum "Credit Status"
begin
    if Utilization >= 100 then
        exit("Credit Status"::Blocked);
    if Utilization >= WarningThreshold then
        exit("Credit Status"::Warning);
    exit("Credit Status"::OK);
end;
```

#### Impure Functions (Isolate)
- **Side effects:** Database, files, HTTP, time, random
- **Isolate in repositories/services**
- **Inject into business logic**

```al
// âœ… Impure function - isolated in repository
codeunit 50101 "Customer Repository"
{
    procedure GetOutstandingAmount(CustomerNo: Code[20]): Decimal
    var
        CustLedgerEntry: Record "Cust. Ledger Entry";
        Outstanding: Decimal;
    begin
        // Impure: database access isolated here
        CustLedgerEntry.SetRange("Customer No.", CustomerNo);
        CustLedgerEntry.SetRange(Open, true);
        if CustLedgerEntry.FindSet() then
            repeat
                Outstanding += CustLedgerEntry."Remaining Amount";
            until CustLedgerEntry.Next() = 0;
        exit(Outstanding);
    end;
}
```

### 4. Repository Pattern for Database Access

**Rule:** Business logic codeunits NEVER access tables directly. Use repositories.

```al
// âŒ BAD - business logic mixed with database access
codeunit 50100 "Order Validator"
{
    procedure ValidateOrder(SalesHeader: Record "Sales Header"): Boolean
    var
        Customer: Record Customer;
        Item: Record Item;
        SalesLine: Record "Sales Line";
    begin
        Customer.Get(SalesHeader."Sell-to Customer No.");
        SalesLine.SetRange("Document Type", SalesHeader."Document Type");
        SalesLine.SetRange("Document No.", SalesHeader."No.");
        if SalesLine.FindSet() then
            repeat
                Item.Get(SalesLine."No.");
                if Item.Blocked then
                    exit(false);
            until SalesLine.Next() = 0;
        // Mixed concerns: validation + data access
    end;
}

// âœ… GOOD - repository handles data, logic is pure
codeunit 50100 "Order Validator"
{
    procedure ValidateOrder(
        OrderHeader: Record "Sales Header";
        CustomerRepo: Interface ICustomerRepository;
        OrderRepo: Interface IOrderRepository
    ): Boolean
    var
        Customer: Record Customer;
        OrderLines: List of [Record "Sales Line"];
        Line: Record "Sales Line";
    begin
        // Get data via repository
        if not CustomerRepo.TryGetCustomer(OrderHeader."Sell-to Customer No.", Customer) then
            exit(false);

        if Customer.Blocked <> Customer.Blocked::" " then
            exit(false);

        // Get order lines via repository
        OrderRepo.GetOrderLines(OrderHeader, OrderLines);

        // Pure business logic
        foreach Line in OrderLines do
            if not ValidateLine(Line, OrderRepo) then
                exit(false);

        exit(true);
    end;

    local procedure ValidateLine(
        Line: Record "Sales Line";
        OrderRepo: Interface IOrderRepository
    ): Boolean
    begin
        // Pure validation logic (item blocking check delegated to repo)
        exit(not OrderRepo.IsItemBlocked(Line."No."));
    end;
}
```

### When to Create Interfaces Checklist

Create an interface when your code needs to:

- [ ] **Access database tables** â†’ `ICustomerRepository`, `IOrderRepository`
- [ ] **Get current time/date** â†’ `ITimeProvider`
- [ ] **Call HTTP APIs** â†’ `IApiClient`, `IHttpService`
- [ ] **Access file system** â†’ `IFileService`
- [ ] **Generate random numbers** â†’ `IRandomProvider`
- [ ] **Send emails/notifications** â†’ `INotificationService`
- [ ] **Log/telemetry** â†’ `ILogger`
- [ ] **Configuration/settings** â†’ `IConfigurationService`

### Testable Architecture Example: Credit Limit Feature

#### Business Logic (Pure)
```al
codeunit 50100 "Credit Limit Validator"
{
    procedure ValidateCreditLimit(
        CustomerNo: Code[20];
        NewOrderAmount: Decimal;
        CustomerRepo: Interface ICustomerRepository;
        OrderRepo: Interface IOrderRepository
    ): Boolean
    var
        Customer: Record Customer;
        Outstanding: Decimal;
        TotalExposure: Decimal;
    begin
        // Get data via repositories (mockable)
        if not CustomerRepo.TryGetCustomer(CustomerNo, Customer) then
            Error('Customer not found');

        if Customer.CreditLimit = 0 then
            exit(true); // Unlimited

        Outstanding := CustomerRepo.GetOutstandingAmount(CustomerNo);
        TotalExposure := Outstanding + NewOrderAmount;

        // Pure business logic
        exit(TotalExposure <= Customer.CreditLimit);
    end;
}
```

#### Test Codeunit
```al
codeunit 50200 "Credit Limit Tests"
{
    Subtype = Test;

    [Test]
    procedure TestCreditLimit_WithinLimit_AllowsOrder()
    var
        Validator: Codeunit "Credit Limit Validator";
        MockCustomerRepo: Codeunit "Mock Customer Repository";
        MockOrderRepo: Codeunit "Mock Order Repository";
        Customer: Record Customer;
        Result: Boolean;
    begin
        // [GIVEN] Customer with 10000 credit limit and 5000 outstanding
        CreateMockCustomer(Customer, 'C001', 10000);
        MockCustomerRepo.AddMockCustomer(Customer, 5000);

        // [WHEN] Validating new order of 3000
        Result := Validator.ValidateCreditLimit(
            'C001',
            3000,
            MockCustomerRepo,
            MockOrderRepo
        );

        // [THEN] Order is allowed (5000 + 3000 = 8000 < 10000)
        Assert.IsTrue(Result, 'Should allow order within credit limit');
    end;

    [Test]
    procedure TestCreditLimit_OverLimit_BlocksOrder()
    var
        Validator: Codeunit "Credit Limit Validator";
        MockCustomerRepo: Codeunit "Mock Customer Repository";
        MockOrderRepo: Codeunit "Mock Order Repository";
        Customer: Record Customer;
        Result: Boolean;
    begin
        // [GIVEN] Customer with 10000 credit limit and 8000 outstanding
        CreateMockCustomer(Customer, 'C001', 10000);
        MockCustomerRepo.AddMockCustomer(Customer, 8000);

        // [WHEN] Validating new order of 3000
        Result := Validator.ValidateCreditLimit(
            'C001',
            3000,
            MockCustomerRepo,
            MockOrderRepo
        );

        // [THEN] Order is blocked (8000 + 3000 = 11000 > 10000)
        Assert.IsFalse(Result, 'Should block order over credit limit');
    end;

    local procedure CreateMockCustomer(
        var Customer: Record Customer;
        CustomerNo: Code[20];
        CreditLimit: Decimal
    )
    begin
        Customer.Init();
        Customer."No." := CustomerNo;
        Customer.CreditLimit := CreditLimit;
    end;
}
```

### Benefits of Testable Architecture

1. **Test Confidence** - Tests that verify mocks = confidence in test correctness
2. **Fast Tests** - No database = tests run in milliseconds
3. **Deterministic** - No time dependencies = reliable tests
4. **Early Design** - Forces thinking about dependencies upfront
5. **No Redesign** - Architecture supports testing from day 1
6. **Clear Boundaries** - Interfaces show what can be mocked

### Migration Strategy for Existing Code

If you have untestable code:

1. **Identify dependencies** - Database, time, HTTP, files
2. **Extract interfaces** - Define IRepository, ITimeProvider, etc.
3. **Inject dependencies** - Add parameters to procedures
4. **Create mocks** - Implement test versions
5. **Write tests** - Use mocks to test business logic
6. **Refactor gradually** - One module at a time

### Key Takeaway

**Design for testability from the start.** Adding tests to untestable code requires massive redesign. With dependency injection and interfaces, tests are natural and give true confidence in correctness.

## ğŸ“ Standard Event Pattern

```al
[EventSubscriber(ObjectType::Table, Database::Customer, 'OnBeforeInsertEvent', '', false, false)]
local procedure OnBeforeInsertCustomer(var Rec: Record Customer)
begin
    // Custom logic here
end;
```

## ğŸ” Error Handling Pattern

```al
if not SomeCondition then
    Error('Clear error message: %1', Value);
```

## ğŸ“‚ Project Structure

- **Related functionality together** in subfolders
- **Separate folders** for tables, pages, codeunits, reports
- **File naming**: `ObjectType.ObjectName.al`

## ğŸ’¡ Common Workflows

### Workflow 0: Quick Bug Fix (Fastest - 5 minutes)
```
1. /fix "Error message or bug description"
2. (Recommended for non-trivial bugs: write failing test first)
3. Review proposed fix
4. Approve â†’ diagnostics run
5. Done! Commit the fix
```

**Best for:**
- Compiler errors
- Small logic bugs
- Validation errors
- Quick corrections

**TDD option:** For logic bugs, write a failing test first to confirm diagnosis. If the test passes immediately, the diagnosis is wrong. See `/fix` command for details.

**Skips:** Planning, design, testing (just fix + verify)

### Workflow A: All-in-One (Fast)
```
1. /dev-cycle "Feature description"
2. Approve each phase when prompted (requirements â†’ solution plan â†’ dev â†’ test)
3. Done! All artifacts in .dev/
```

### Workflow B: Plan First, Implement Later (Recommended)
```
Session 1 - Planning:
1. /plan "Feature description"
2. Approve requirements â†’ solution plan
3. Review .dev/02-solution-plan.md carefully offline
4. Share plan with team if needed
5. Stop here

Session 2 - Implementation (same day or later):
6. /develop
   OR /dev-cycle "..." (will detect existing plan and ask to reuse)
7. Agent implements code based on approved plan
8. Review .dev/03-code-review.md
9. Done with development

Session 3 - Testing:
10. /test
11. Review .dev/06-test-review.md
12. Complete!
```

**Why Workflow B is better:**
- Planning can be reviewed at your pace
- No pressure during approval gates
- Can implement hours/days later
- Team can review plan before coding starts
- Separates thinking from doing

### Starting a New Feature (Detailed)
```
1. /dev-cycle "Feature description"
2. Review .dev/01-requirements.md - approve or refine
3. Review .dev/02-solution-plan.md - approve architecture & implementation plan
4. Agent implements code
5. Review .dev/03-code-review.md
6. Agent fixes diagnostics
7. Agent writes tests
8. Review .dev/06-test-review.md
9. Done!
```

### Debugging Existing Code
```
1. /diagnostics-fixer
2. Review .dev/04-diagnostics.md
3. Agent fixes issues
4. Recompile, verify
```

### Understanding Base App Integration
```
1. /nav-baseapp "Find Customer posting events"
2. Review .dev/nav-customer-events.md
3. /bc-expert "Best practice for extending Customer posting"
4. Review .dev/expert-posting-patterns.md
5. Implement with guidance
```

### Code Review Existing Changes
```
1. /code-reviewer
2. Review .dev/03-code-review.md
3. Address findings
4. /diagnostics-fixer
5. Verify improvements
```

## ğŸ“ When to Use Support Agents

### bc-expert
- Complex BC patterns (posting routines, integration patterns)
- Architecture decisions (how to extend base app)
- Performance optimization strategies
- Security concerns (permission sets, field security)

### docs-lookup
- Official Microsoft documentation needed
- API reference for base app objects
- AL language features and syntax
- Breaking changes in BC versions

### dependency-navigator
- Find base app objects and their structure
- Understand table relationships
- Locate events and extension points
- Explore existing extension patterns

## ğŸ“Š Session Log Format

`.dev/session-log.md` tracks all agent activity:

```markdown
# Development Session Log

**Started:** 2026-01-14 10:30:00
**Project:** Customer Credit Limit Feature

## [10:30:15] requirements-engineer
- Input: "Add customer credit limit validation"
- Extracted 5 functional requirements
- Identified 2 base app touchpoints
- Output: .dev/01-requirements.md
- Status: âœ“ Complete

## [10:32:40] solution-planner
- Input: .dev/01-requirements.md
- Consulted BC MCP for Customer table extension patterns
- Researched MS Docs for validation patterns
- Explored base app objects
- Designed event subscriber approach with 2 extensions
- Planned step-by-step implementation (3 files, 4 phases)
- Output: .dev/02-solution-plan.md
- Status: âœ“ Complete

[... continues ...]
```

## ğŸ”„ Iteration & Refinement

Agents support iterative refinement:

```
User: "Actually, let's use a separate validation codeunit instead"

Claude: [spawns solution-planner again]
Agent: [reads 01+02, applies new constraint, updates 03]
Agent: "Implementation plan revised â†’ .dev/02-solution-plan.md"
```

All previous context preserved in documents - agents adapt to feedback.

## âœ… Success Criteria

A complete development cycle produces:
- âœ“ Clear requirements document
- âœ“ Comprehensive solution plan (architecture + implementation)
- âœ“ Working AL code
- âœ“ Code review with findings
- âœ“ Clean compilation (no errors)
- âœ“ Comprehensive tests
- âœ“ Test review confirmation

**All documented in `.dev/` for future reference.**

---

*This profile enables full-lifecycle AL development with collaborative agents and document-driven workflow.*


<claude-mem-context>
# Recent Activity

<!-- This section is auto-generated by claude-mem. Edit content outside the tags. -->

### Jan 30, 2026

| ID | Time | T | Title | Read |
|----|------|---|-------|------|
| #313 | 3:48 PM | âœ… | REFACTOR Phase: Updated to Use bc-test Multi-Codeunit and File Output | ~435 |
| #265 | 2:21 PM | ğŸŸ£ | README Documentation: Added Automated Test Execution Section for v2.20+ | ~587 |
| #264 | 2:20 PM | âœ… | Profile Version Bumped from 2.15.0 to 2.20.0 in README | ~304 |
| #248 | 2:18 PM | âœ… | Added BC Configuration Requirements and Updated Hard Stops Summary | ~549 |
| #246 | 2:17 PM | âœ… | GREEN Phase Updated: Automated Compile, Publish, and Test Execution | ~424 |
| #244 | " | âœ… | TDD Workflow Updated: Automated Test Execution with bc-publish and bc-test | ~471 |
| #242 | 2:16 PM | âš–ï¸ | TDD Workflow with Mandatory Manual Approval Gates | ~754 |

### Feb 6, 2026

| ID | Time | T | Title | Read |
|----|------|---|-------|------|
| #1358 | 7:21 AM | ğŸ”µ | Current CLAUDE.md Defines Document-Driven Multi-Agent Workflow | ~635 |
</claude-mem-context>